### Deep Learning
- What is Neural Network?
- How Are Weights Initialized in a Network?
- Describe feed forward and back propagation in neural network
- What Is a Multi-layer Perceptron(MLP)?
- What is activation function? Why are thy important? Can you create a neural network without activation function?
- What Is the Difference Between a Feedforward Neural Network and Recurrent Neural Network?
- What is loss function? What is cost function?
- What is word embedding? How do you create a word embedding?
- Is GloVe better than Word2Vec?
- Is FastText better than GloVe?
- What do you do with train, validation and test set in deep learning?
- What is batch normalization?
- What is optimizer? How do you select optimiser?
- While training a model, we compile the model with three things: loss, optimizer, accuracy. What is the importance of these three things?
- What is basic difference between loss and accuracy? Don't they sound same?
- What is hyper-parameter tuning in deep learning?
- What Will Happen If the Learning Rate Is Set Too Low or Too High?
- How do you calculate parameters in fully connected neural network?
- What is batch size and epoch? How does this affect the training and validation accuracy?
- What do you mean by batch size 1000 and epoch 10? How many times do you update the wight matrices if you train the model with 1 million sample data?
- What is Adam Optimizer?
- How do you know you are over fitting?
- What is callback in deep learning?
- What if we use learning rate that is too large?

### Convolutional Neural Network
- What is convolutional neural network?
- What is the Boltzmann Machine?
- What Are the Different Layers on CNN?
- What is feed forward and back propagation in neural network?
- Explain a Computational Graph.
- What happens to the dimension of the output of 2d image (28x28) after implementation of filter of size 3 and padding of size 1?
- Why is pooling used in CNN? How does it reduce the dimension of the feature?
- What is parameter sharing and local connectivity in CNN?
- What is drop out in CNN?
- How do you set drop out with hyper-parameter setting in CNN?
- Where can I dropout of CNN?
- What Is the Difference Between Epoch, Batch, and Iteration in Deep Learning?
- What is auto-encoder?

### Transfer Learning
- What is transfer learning?
- Describe some established transfer learning network.
- Describe VGG net in detail for number of layers and parameters involved
- What is the difference between AlexNet, VGGNet, ResNet, and Inception?

### Recurrent Neural Network
- What is recurrent neural network?
- What are the equations of simple RNN model?
- What do you mean by unrolling of RNN network?
- Describe back propagation in simple RNN model.
- How do you connect Fully connected layer after RNN layer?
- What is time distributed layer in RNN with LSTM cells?
- How do you select the number of cell in RNN?
- What are different output model in RNN?
- What are vanishing and exploding gradient problem in simple RNN model?
- What is limitation of simple RNN for long term memory?
- What is LSTM?
- Describe internal structure of LSTM cell.
- How many parameters are needed to be trained in single LSTM cell?
- What is the dimension of the input and output of the LSTM cell?
- Describe Feed Forward and Back-propagation in LSTM.
- What is GRU?
- What is difference between simple RNN, LSTM, and GRU?
- What is vanilla LSTM?
- How does data flow in multi-layered LSTM network?
- What is encoder-decoder LSTM?
- What are use cases of Encoder-Decoder LSTM?
- What is bidirectional LSTM? When do you use them?
- What are the limitation of LSTM based models?
- What is attention Mechanism?
- Describe attention mechanism in CNN.
- Describe attention mechanism in Encoder-Decoder network.
- What is a Transformer?
- What is positional encoding in transformer network?
- What is multi head attention in Transformer?
- Describe structure of transformer in detail.
- How many parameters are there to be trained in Transformer network?
- What are the use cases of Transformer.
- How one can use transformer for language translation?
- How one can use transformer for document summarizing?
- How one can use transformer for NER?
- How one can use transformer for sequence analysis?
- What is BERT?
- What is difference between LSTM and Transformer?






















































- 
